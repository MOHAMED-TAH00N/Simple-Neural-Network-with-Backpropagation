{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "foqhoMDbiWzS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "def tanh_derivative(x):\n",
        "    return 1 - tanh(x) ** 2\n"
      ],
      "metadata": {
        "id": "Ub2YVJMQho0K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(inputs, weights, biases):\n",
        "    net_h1 = weights['w1'] * inputs[0] + weights['w2'] * inputs[1] + biases['b1']\n",
        "    net_h2 = weights['w3'] * inputs[0] + weights['w4'] * inputs[1] + biases['b2']\n",
        "\n",
        "    out_h1 = tanh(net_h1)\n",
        "    out_h2 = tanh(net_h2)\n",
        "\n",
        "    net_o1 = weights['w5'] * out_h1 + weights['w6'] * out_h2\n",
        "    net_o2 = weights['w7'] * out_h1 + weights['w8'] * out_h2\n",
        "\n",
        "    out_o1 = tanh(net_o1)\n",
        "    out_o2 = tanh(net_o2)\n",
        "\n",
        "    return out_h1, out_h2, out_o1, out_o2, net_h1, net_h2, net_o1, net_o2\n"
      ],
      "metadata": {
        "id": "KYPKHYwkhuGI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(inputs, weights, biases, targets, learning_rate):\n",
        "    out_h1, out_h2, out_o1, out_o2, net_h1, net_h2, net_o1, net_o2 = forward_pass(inputs, weights, biases)\n",
        "\n",
        "    error_o1 = (out_o1 - targets[0]) * tanh_derivative(net_o1)\n",
        "    error_o2 = (out_o2 - targets[1]) * tanh_derivative(net_o2)\n",
        "\n",
        "    weights['w5'] -= learning_rate * error_o1 * out_h1\n",
        "    weights['w6'] -= learning_rate * error_o1 * out_h2\n",
        "    weights['w7'] -= learning_rate * error_o2 * out_h1\n",
        "    weights['w8'] -= learning_rate * error_o2 * out_h2\n",
        "\n",
        "    error_h1 = (error_o1 * weights['w5'] + error_o2 * weights['w7']) * tanh_derivative(net_h1)\n",
        "    error_h2 = (error_o1 * weights['w6'] + error_o2 * weights['w8']) * tanh_derivative(net_h2)\n",
        "\n",
        "    weights['w1'] -= learning_rate * error_h1 * inputs[0]\n",
        "    weights['w2'] -= learning_rate * error_h1 * inputs[1]\n",
        "    weights['w3'] -= learning_rate * error_h2 * inputs[0]\n",
        "    weights['w4'] -= learning_rate * error_h2 * inputs[1]\n",
        "\n",
        "    biases['b1'] -= learning_rate * error_h1\n",
        "    biases['b2'] -= learning_rate * error_h2"
      ],
      "metadata": {
        "id": "ubSZBCharDb-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_neural(inputs, targets, weights, biases, learning_rate, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        backward_pass(inputs, weights, biases, targets, learning_rate)\n",
        "        out_h1, out_h2, out_o1, out_o2, _, _, _, _ = forward_pass(inputs, weights, biases)\n",
        "        loss = 0.5 * ((targets[0] - out_o1) ** 2 + (targets[1] - out_o2) ** 2)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {loss:.6f}, o1 = {out_o1:.6f}, o2 = {out_o2:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qKldKoS4qHWt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([0.05, 0.1])\n",
        "targets = np.array([0.01, 0.99])\n",
        "\n",
        "weights = {key: np.random.uniform(-0.5, 0.5) for key in ['w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8']}\n",
        "biases = {'b1': 0.5, 'b2': 0.7}\n",
        "\n",
        "train_neural(inputs, targets, weights, biases, learning_rate=0.1, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJCViGPPrLEr",
        "outputId": "ce3b7c40-1ceb-4b5e-b8a8-1e21205daf37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 0.606499, o1 = -0.127634, o2 = -0.102728\n",
            "Epoch 2: Loss = 0.526771, o1 = -0.113034, o2 = -0.029022\n",
            "Epoch 3: Loss = 0.458892, o1 = -0.100199, o2 = 0.038349\n",
            "Epoch 4: Loss = 0.401184, o1 = -0.088874, o2 = 0.099724\n",
            "Epoch 5: Loss = 0.352068, o1 = -0.078834, o2 = 0.155588\n",
            "Epoch 6: Loss = 0.310184, o1 = -0.069887, o2 = 0.206427\n",
            "Epoch 7: Loss = 0.274401, o1 = -0.061876, o2 = 0.252684\n",
            "Epoch 8: Loss = 0.243771, o1 = -0.054674, o2 = 0.294759\n",
            "Epoch 9: Loss = 0.217504, o1 = -0.048177, o2 = 0.333020\n",
            "Epoch 10: Loss = 0.194928, o1 = -0.042302, o2 = 0.367810\n",
            "Epoch 11: Loss = 0.175476, o1 = -0.036978, o2 = 0.399453\n",
            "Epoch 12: Loss = 0.158668, o1 = -0.032145, o2 = 0.428253\n",
            "Epoch 13: Loss = 0.144096, o1 = -0.027754, o2 = 0.454494\n",
            "Epoch 14: Loss = 0.131417, o1 = -0.023761, o2 = 0.478439\n",
            "Epoch 15: Loss = 0.120345, o1 = -0.020130, o2 = 0.500325\n",
            "Epoch 16: Loss = 0.110636, o1 = -0.016825, o2 = 0.520369\n",
            "Epoch 17: Loss = 0.102090, o1 = -0.013818, o2 = 0.538766\n",
            "Epoch 18: Loss = 0.094536, o1 = -0.011083, o2 = 0.555687\n",
            "Epoch 19: Loss = 0.087833, o1 = -0.008596, o2 = 0.571287\n",
            "Epoch 20: Loss = 0.081861, o1 = -0.006334, o2 = 0.585703\n",
            "Epoch 21: Loss = 0.076521, o1 = -0.004279, o2 = 0.599055\n",
            "Epoch 22: Loss = 0.071728, o1 = -0.002413, o2 = 0.611449\n",
            "Epoch 23: Loss = 0.067409, o1 = -0.000720, o2 = 0.622980\n",
            "Epoch 24: Loss = 0.063506, o1 = 0.000815, o2 = 0.633731\n",
            "Epoch 25: Loss = 0.059966, o1 = 0.002206, o2 = 0.643776\n",
            "Epoch 26: Loss = 0.056745, o1 = 0.003465, o2 = 0.653180\n",
            "Epoch 27: Loss = 0.053806, o1 = 0.004603, o2 = 0.662002\n",
            "Epoch 28: Loss = 0.051116, o1 = 0.005630, o2 = 0.670292\n",
            "Epoch 29: Loss = 0.048647, o1 = 0.006557, o2 = 0.678098\n",
            "Epoch 30: Loss = 0.046376, o1 = 0.007391, o2 = 0.685459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9CCgUKMrX-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}