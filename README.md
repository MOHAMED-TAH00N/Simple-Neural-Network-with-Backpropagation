# Simple-Neural-Network-with-Backpropagation
This code implements a simple two-layer neural network using the tanh activation function. It includes forward propagation, backpropagation, and gradient descent to update weights and biases. The network is trained to minimize error over multiple epochs
